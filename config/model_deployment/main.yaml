# Agent 主模型 (文本生成文本) - vLLM 部署

model_id: "models/Qwen3-30B-A3B-Instruct-2507-FP8"
backend: vllm

# vLLM 启动参数 (对应 .env 中 LLM_MAIN_BASE_URL 的服务)
vllm:
  host: "0.0.0.0"
  port: 8000
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.9
  max_model_len: 8192
